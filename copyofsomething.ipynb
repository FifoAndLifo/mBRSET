{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eacc35dd-f659-4158-8dee-baaa4c9dd56f",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Setting up Environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5626178-beb9-495d-822a-24ed564362c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.get_dataset import get_dataset, split_data\n",
    "from src.data_loader import BRSETDataset, process_labels\n",
    "from src.RetFound import get_retfound\n",
    "from src.FocalLoss import FocalLoss\n",
    "from src.model import FoundationalCVModel, FoundationalCVModelWithClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.train import train\n",
    "from src.test import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbf9f70-7796-4ef2-8e0f-b5ffbcd17737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants:\n",
    "DATASET = '/opc/davidres/retina/mbrset/data'\n",
    "DOWNLOAD = False\n",
    "SHAPE = (224, 224)\n",
    "IMAGES = os.path.join(DATASET, 'mBRSET/')\n",
    "LABEL = 'final_icdr'\n",
    "TEST_SIZE = 0.3\n",
    "UNDERSAMPLE = False\n",
    "\n",
    "LABELS_PATH = os.path.join(DATASET, 'labels.csv')\n",
    "IMAGE_COL = 'file'\n",
    "\n",
    "\"\"\"\n",
    "Dataset Mean and Std:\n",
    "NORM_MEAN = [0.5896205017400412, 0.29888971649817453, 0.1107679405196557]\n",
    "NORM_STD = [0.28544273712830986, 0.15905456049750208, 0.07012281660980953]\n",
    "\n",
    "ImageNet Mean and Std:\n",
    "NORM_MEAN = [0.485, 0.456, 0.406]\n",
    "NORM_STD = [0.229, 0.224, 0.225]\n",
    "\"\"\"\n",
    "\n",
    "NORM_MEAN = None # [0.485, 0.456, 0.406]\n",
    "NORM_STD = None # [0.229, 0.224, 0.225]\n",
    "\n",
    "BACKBONE = 'dinov2_large'\n",
    "MODE = 'fine_tune'\n",
    "backbone_mode = 'fine_tune'\n",
    "\n",
    "HIDDEN = [128]\n",
    "num_classes = 3\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "LOSS = None #'focal_loss'\n",
    "OPTIMIZER = 'adam'\n",
    "\n",
    "# Define your hyperparameters\n",
    "num_epochs = 50\n",
    "learning_rate = 1e-5\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468abe47-5a3b-452b-bf09-4f7e7f52531b",
   "metadata": {},
   "source": [
    "## Read CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c67856-54e2-4d38-b271-5d4ab10e0b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_dataset(DATASET, download=DOWNLOAD, info=False)\n",
    "df = df[df['file'] != '985.1.jpg'] # this is missing\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87d7ad8-81be-4741-8bc2-2d49ee39503f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert into 3 classes:\n",
    "\n",
    "# Normal = 0; Non-proliferative = 1, 2, 3; Proliferative = 4\n",
    "# Map values to categories\n",
    "df[LABEL] = df[LABEL].apply(lambda x: 'Normal' if x == 0 else ('Non-proliferative' if x in [1, 2, 3] else 'Proliferative'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b268bb-05eb-4c15-9b72-a70d50d5f918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train, test and validation:\n",
    "df_train, df_test = split_data(df, LABEL, TEST_SIZE, undersample=False)\n",
    "print('Getting validation set...')\n",
    "df_test, df_val = split_data(df_test, LABEL, 0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7d2d40-8594-4106-9348-ea767d42cccf",
   "metadata": {},
   "source": [
    "## Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27a1c7a-402f-4a98-97b2-fa17f7beba31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the one hot encoder on the train set and get the labels for the test and validation sets:\n",
    "train_labels, mlb, train_columns = process_labels(df_train, col=LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cb9562-47bb-456b-9dc4-0d8664d486a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target image shape\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop(SHAPE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "    transforms.RandomRotation(50),  # Randomly rotate the image by up to 10 degrees\n",
    "])\n",
    "\n",
    "if NORM_MEAN is not None and NORM_STD is not None:\n",
    "    train_transforms.transforms.append(transforms.Normalize(mean=NORM_MEAN, std=NORM_STD))\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(SHAPE),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "if NORM_MEAN is not None and NORM_STD is not None:\n",
    "    test_transform.transforms.append(transforms.Normalize(mean=NORM_MEAN, std=NORM_STD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0821ee-4efa-4488-b787-1bef6de38209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the custom dataset\n",
    "train_dataset = BRSETDataset(\n",
    "    df_train, \n",
    "    IMAGE_COL, \n",
    "    IMAGES, \n",
    "    LABEL, \n",
    "    mlb, \n",
    "    train_columns, \n",
    "    transform=train_transforms\n",
    ")\n",
    "\n",
    "test_dataset = BRSETDataset(\n",
    "    df_test, \n",
    "    IMAGE_COL, \n",
    "    IMAGES, \n",
    "    LABEL, \n",
    "    mlb, \n",
    "    train_columns, \n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "val_dataset = BRSETDataset(\n",
    "    df_val, \n",
    "    IMAGE_COL, \n",
    "    IMAGES, \n",
    "    LABEL, \n",
    "    mlb, \n",
    "    train_columns, \n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1809c2-49d7-4d51-8f73-742e9a908b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the custom dataset\n",
    "train_dataset = BRSETDataset(\n",
    "    df_train, \n",
    "    IMAGE_COL, \n",
    "    IMAGES, \n",
    "    LABEL, \n",
    "    mlb, \n",
    "    train_columns, \n",
    "    transform=train_transforms\n",
    ")\n",
    "\n",
    "test_dataset = BRSETDataset(\n",
    "    df_test, \n",
    "    IMAGE_COL, \n",
    "    IMAGES, \n",
    "    LABEL, \n",
    "    mlb, \n",
    "    train_columns, \n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "val_dataset = BRSETDataset(\n",
    "    df_val, \n",
    "    IMAGE_COL, \n",
    "    IMAGES, \n",
    "    LABEL, \n",
    "    mlb, \n",
    "    train_columns, \n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdc586f-7884-4d5c-bbe1-1ba6b26ee423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print 6 samples with their labels\n",
    "# Iterate through the DataLoader and plot the images with labels\n",
    "\n",
    "for batch in train_dataloader:\n",
    "\n",
    "    images, labels = batch['image'], batch['labels']\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        if i == 6:\n",
    "            break\n",
    "        plt.subplot(2, 3, i + 1)\n",
    "        plt.imshow(images[i].permute(1, 2, 0))  # Permute to (H, W, C) from (C, H, W)\n",
    "        plt.title(f\"Label: {np.argmax(labels[i])}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf515ee-93ad-4bea-8d49-1ff1d83d6f20",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76baf92-a5fc-4d3f-957a-0c458de81eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader to generate embeddings\n",
    "#model = get_retfound(weights='/scratch/liyues_root/liyues/chenweiw/retina_datasets/retfound_weigths/RETFound_cfp_weights.pth', num_classes=3)\n",
    "# Create a DataLoader to generate embeddings\n",
    "backbone_model = FoundationalCVModel(backbone=BACKBONE, mode=MODE)\n",
    "model = FoundationalCVModelWithClassifier(backbone_model, hidden=HIDDEN, num_classes=num_classes, mode=MODE, backbone_mode=backbone_mode)\n",
    "model.to(device)\n",
    "\n",
    "# Use DataParallel to parallelize the model across multiple GPUs\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model, [0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43f4c32-c625-47cb-b884-ab006f704a64",
   "metadata": {},
   "source": [
    "## Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf81713-edbe-4826-9a47-2edd62f65180",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOSS == 'focal_loss':\n",
    "    class_distribution = train_dataloader.dataset.labels.sum(axis=0)\n",
    "    print(f'Class distribution: {class_distribution}')\n",
    "    class_dis = np.array(class_distribution)\n",
    "    class_weights =1-class_dis/np.sum(class_dis)\n",
    "    weights = torch.tensor(class_weights).to(device)\n",
    "    #criterion = FocalLoss()  # Focal Loss\n",
    "    criterion = FocalLoss(gamma=2, alpha=weights)\n",
    "else:\n",
    "    # Assuming train_loader.dataset.labels is a one-hot representation\n",
    "    class_indices = np.argmax(train_dataloader.dataset.labels, axis=1)\n",
    "\n",
    "    # Compute class weights using class indices\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(class_indices), y=class_indices)\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights).to(device)\n",
    "    #criterion = nn.BCEWithLogitsLoss() # Binary Cross-Entropy Loss\n",
    "\n",
    "if OPTIMIZER == 'adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "elif OPTIMIZER == 'adamw':\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "else:\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bf08c6-d14a-4061-9d5c-a76406296632",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train(model, train_dataloader, val_dataloader, criterion, optimizer, num_epochs=num_epochs, save=True, device=device, backbone=f'convnextv2_3class_{LABEL}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fcae62-7462-41d3-a8e0-b011d8bf4418",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9309670d-d203-4a20-a241-7a3ec0087f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model, test_dataloader, saliency=True, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
